---
title: Sentiment Analysis of Psalms
author: AmandaRP
date: '2019-05-18'
slug: text-analysis-of-psalms
draft: true
categories: []
tags: []
---

```{r setup, include = FALSE}
library(wordcloud)
library(tidytext)
library(sentimentr)
library(tidyverse)
library(magrittr)
library(rvest)
```

[Psalms](https://www.biblegateway.com/quicksearch/?quicksearch=psalms&qs_version=GNT) is a book in both the Christian Bible and the Jewish Torah. I thought it would be interesting to look at a sentiment analysis of the book.    

I chose to work with the "Good New Translation" of the bible as it does not have copyright issues like some of the other translations (per the [American Bible Society](https://scripture.api.bible/)). We'll use the [tidytext](https://CRAN.R-project.org/package=tidytext) and [sentimentr](https://CRAN.R-project.org/package=sentimentr) R packages to do the analysis.

TODO:

* Spell check
* Comparison cloud of positive and negative words
* Add reference and link to tidytext book

Let's start by reading data from [biblegateway.com](biblegateway.com) (using [rvest](https://CRAN.R-project.org/package=rvest)) and doing a bit of cleaning:

```{r, cache=TRUE}

#Pull text and do a bit of cleaning:
get_chapter <- function(chapter){
  
  url <- str_c("https://www.biblegateway.com/passage/?search=Psalms+", 
               chapter, 
               "&version=GNT")
  
  html <- read_html(url)
  
  text <- html %>% 
    html_node(".passage-wrap") %>% 
    html_text() %>%
    str_extract("\\(GNT.{1,}") %>%
    str_replace("\\(GNT\\)","") %>%
    str_extract("\\d.{1,}") %>%
    str_replace_all("\\d{1,}", "") %>%
    str_replace_all("\\[\\w{1}\\]","")
}

#Use the function defined above to read all 150 chapters.
chapters <- map_chr(1:150, get_chapter) %>% 
  tibble::enframe(name = "ch_num", value = "text") 
```


# Sentiment Analysis by Chapter

Next, we'll use the `tidytext` package to join our data with a dictionary of sentiment words. For more information about using text analysis using `tidytext`, see [Text Mining with R: A Tidy Approach](www.tidytextmining.com/) by Julia Silge and David Robinson. `tidytext` comes with sentiment dictionaries, but I'm going to use the Jockers & Rinker sentiment dictionary from the [lexicon](https://CRAN.R-project.org/package=lexicon) package to better compare with a follow-on analysis using the `sentimentr` package. This dictionary contains positive and negative words and an associated sentiment score in the range [-1, 1]. A value of 1 is the most positive, 0 is neutral, and negative 1 is most negative. 

There is some flexibility in the method that we choose to compute the sentiment. We could *sum* the sentiment scores for the words in each chapter, which introduces a relationship between sentiment score and chapter length. Or we could compute the *average* sentiment over the words in the chapter, either chooseing to ignore or include neutral words (i.e. words with score of 0). The inclusion of neutral words in the calculation of the average would dampen the overall sentiment score of the chapter. I think the choice depends on what makes the most sense for each application. 

In the interest of better comparing this first calculation to a second calculation using the sentimentr pakcage, I'm going to divide the sum of the word sentiment scores by the square root of the number of words in the chapter (including neutral words). That is, the sentiment for chapter $j$ will be

$$S_j =  \frac{\sum_{i=1}^{n_j} s_{ij}}{\sqrt{n_j}} $$

where $n_j$ is the words count for chapter $j$ and $s_{ij}$ is the sentiment score for the i^{th} word in chapter $j$.  


```{r}
psalms_sentiment_jockers_rinker <- chapters %>% 
  unnest_tokens(word, text) %>%  #tokenize by words
  #anti_join(stop_words) %>%
  left_join(lexicon::hash_sentiment_jockers_rinker, 
             by = c("word" = "x"), 
             drop = FALSE) %>%
  mutate(y = replace_na(y, 0)) %>%
  group_by(ch_num) %>%
  summarize(avg_sentiment = sum(y)/sqrt(n()))

#Find min and max sentiment chapters. Add annotation to graph.
max_sentiment <- psalms_sentiment_jockers_rinker %>% 
  top_n(1, avg_sentiment) 

min_sentiment <- psalms_sentiment_jockers_rinker %>% 
  top_n(-1, avg_sentiment) 

#Plot:
ggplot(psalms_sentiment_jockers_rinker, 
       aes(ch_num, avg_sentiment, 
           fill = avg_sentiment>0)) +
  geom_col(show.legend = FALSE) +
  labs(x = "Chapter Number", 
       y = "Sentiment",
       title = "Sentiment of Psalms") +
  theme_minimal() +
  theme(axis.text.y = element_blank(),
        plot.background = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.major.x = element_line(linetype = "dashed", color = "darkgrey"),
        panel.grid.minor.x = element_blank(),
        plot.title = element_text(size = 18)) +
  annotate("text", 
           x = min_sentiment$ch_num + 20, 
           y = min_sentiment$avg_sentiment, 
           label = sprintf("Chapter %d", min_sentiment$ch_num)) +
  geom_curve(aes(x = min_sentiment$ch_num + 11, 
                 y = min_sentiment$avg_sentiment, 
                 xend = min_sentiment$ch_num, 
                 yend = min_sentiment$avg_sentiment), 
             curvature = 0, 
             arrow = arrow(length=unit(2,"mm")), 
             color = "darkgrey") +
  annotate("text", 
           x = max_sentiment$ch_num - 20, 
           y = max_sentiment$avg_sentiment, 
           label = sprintf("Chapter %d", max_sentiment$ch_num)) +
  geom_curve(aes(x = max_sentiment$ch_num - 11, 
                 y = max_sentiment$avg_sentiment, 
                 xend = max_sentiment$ch_num, 
                 yend = max_sentiment$avg_sentiment), 
             curvature = 0, 
             arrow = arrow(length=unit(2,"mm")), 
             color = "darkgrey") 
  
```


We see that [Chapter `r max_sentiment$ch_num`](`r str_c("https://www.biblegateway.com/passage/?search=Psalms+", min_sentiment$ch_num, "&version=GNT")
`) is the most positive and [Chapter `r min_sentiment$ch_num`](`r str_c("https://www.biblegateway.com/passage/?search=Psalms+", max_sentiment$ch_num, "&version=GNT")`) is the most negative. 

Next let's take another look at the sentiment using the sentimentr package. It has some nice features such as valence shifters, which are described on the [package GitHub page](https://github.com/trinker/sentimentr) as follows:

> So what are these valence shifters? A negator flips the sign of a polarized word (e.g., "I do not like it."). An amplifier (intensifier) increases the impact of a polarized word (e.g., "I really like it."). A de-amplifier (downtoner) reduces the impact of a polarized word (e.g., "I hardly like it."). An adversative conjunction overrules the previous clause containing a polarized word (e.g., "I like it but it's not worth it."). 

```{r}
psalms_sentiment_w_valence <- chapters %>%
    get_sentences() %$%
    sentiment_by(text, by = ch_num)

#Find min and max sentiment chapters. Add annotation to graph.
max_sentiment <- psalms_sentiment_w_valence %>% 
  top_n(1, ave_sentiment) 

min_sentiment <- psalms_sentiment_w_valence %>% 
  top_n(-1, ave_sentiment) 

#Plot:
ggplot(psalms_sentiment_w_valence, aes(ch_num, ave_sentiment, fill = ave_sentiment>0)) +
  geom_col(show.legend = FALSE) +
  labs(x = "Chapter Number", 
       y = "Sentiment",
       title = "Sentiment of Psalms (with valence shifters)") +
  theme_minimal() +
  theme(axis.text.y = element_blank(),
        plot.background = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.major.x = element_line(linetype = "dashed", color = "darkgrey"),
        panel.grid.minor.x = element_blank(),
        plot.title = element_text(size = 18)) +
  annotate("text", 
           x = min_sentiment$ch_num + 20, 
           y = min_sentiment$ave_sentiment, 
           label = sprintf("Chapter %d", min_sentiment$ch_num)) +
  geom_curve(aes(x = min_sentiment$ch_num + 11, 
                 y = min_sentiment$ave_sentiment, 
                 xend = min_sentiment$ch_num, 
                 yend = min_sentiment$ave_sentiment), 
             curvature = 0, 
             arrow = arrow(length=unit(2,"mm")), 
             color = "darkgrey") +
  annotate("text", 
           x = max_sentiment$ch_num - 20, 
           y = max_sentiment$ave_sentiment, 
           label = sprintf("Chapter %d", max_sentiment$ch_num)) +
  geom_curve(aes(x = max_sentiment$ch_num - 11, 
                 y = max_sentiment$ave_sentiment, 
                 xend = max_sentiment$ch_num, 
                 yend = max_sentiment$ave_sentiment), 
             curvature = 0, 
             arrow = arrow(length=unit(2,"mm")), 
             color = "darkgrey") 
```

```{r, echo = FALSE}
flip_ch <- inner_join(psalms_sentiment_jockers_rinker, psalms_sentiment_w_valence) %>%
  filter(sign(avg_sentiment * ave_sentiment) < 0) %>%
  mutate(diff = abs(avg_sentiment - ave_sentiment)) %>%
  top_n(1, diff) %>%
  select(ch_num)

```


Now, after taking valence shifters into account, [Chapter `r max_sentiment$ch_num`](`r str_c("https://www.biblegateway.com/passage/?search=Psalms+", max_sentiment$ch_num, "&version=GNT")`) is the most positive and [Chapter `r min_sentiment$ch_num`](`r str_c("https://www.biblegateway.com/passage/?search=Psalms+", min_sentiment$ch_num, "&version=GNT")`) is the most negative. Additionally, between the two analyses, [Chapter `r flip_ch`](`r str_c("https://www.biblegateway.com/passage/?search=Psalms+", flip_ch, "&version=GNT")`) switched from a slightly negative sentiment to a somewhat positive sentiment. 

Have comments or feedback? Message me on Twitter: [AmandaRPlunkett](twitter.com/AmandaRPlunkett)
